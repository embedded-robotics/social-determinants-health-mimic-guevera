{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "import openai\n",
    "from prompts import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_ground_truth = pd.read_csv('eval_employment_prompt.csv')\n",
    "relation_ground_truth = pd.read_csv('eval_relationship_prompt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_ground_truth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_ground_truth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_df = relation_ground_truth[['RELATIONSHIP_nonadverse', 'RELATIONSHIP_adverse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = employment_ground_truth.join(relation_df, on='index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('azure_credentials.json', 'r') as file:\n",
    "    azure_data = json.load(file)\n",
    "    api_key = azure_data['API_KEY']\n",
    "    api_version = azure_data['API_VERSION']\n",
    "    azure_endpoint = azure_data['AZURE_ENDPOINT']\n",
    "    azure_deployment_name = azure_data['AZURE_DEPLOYMENT_NAME']\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint = azure_endpoint\n",
    "    )\n",
    "\n",
    "deployment_name=azure_deployment_name #This will correspond to the custom name you chose for your deployment when you deployed a model. Use a gpt-35-turbo-instruct deployment.\n",
    "\n",
    "# Defining a function to create the prompt from the instruction system message, the few-shot examples, and the current query\n",
    "def create_prompt(system_message, user_message):    \n",
    "    formatted_message = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    return formatted_message\n",
    "\n",
    "# This function sends the prompt to the GPT model\n",
    "def send_message(message, model_name, max_response_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=message,\n",
    "        temperature=0,\n",
    "        max_tokens=max_response_tokens,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_nonadverse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_nonadverse'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_nonadverse_step1 = pd.DataFrame({'index': index_list, 'llm_employment_nonadverse': llm_response_list})\n",
    "\n",
    "with open('llm_employment_nonadverse_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_nonadverse_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_adverse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_adverse'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_adverse_step1 = pd.DataFrame({'index': index_list, 'llm_employment_adverse': llm_response_list})\n",
    "\n",
    "with open('llm_employment_adverse_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_adverse_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_nonadverse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_nonadverse'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_nonadverse_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_nonadverse': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_nonadverse_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_nonadverse_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_adverse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_adverse'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_adverse_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_adverse': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_adverse_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_adverse_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TRANSPORTATION_distance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['TRANSPORTATION_distance'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_transportation_distance_step1 = pd.DataFrame({'index': index_list, 'llm_transportation_distance': llm_response_list})\n",
    "\n",
    "with open('llm_transportation_distance_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_transportation_distance_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TRANSPORTATION_resource'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TRANSPORTATION_other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['HOUSING_poor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['HOUSING_poor'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_housing_poor_step1 = pd.DataFrame({'index': index_list, 'llm_housing_poor': llm_response_list})\n",
    "\n",
    "with open('llm_housing_poor_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_housing_poor_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['HOUSING_undomiciled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['HOUSING_other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_married'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_married'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_married_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_married': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_married_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_married_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_partnered'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_partnered'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_partnered_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_partnered': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_partnered_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_partnered_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_divorced'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_divorced'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_divorced_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_divorced': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_divorced_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_divorced_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_widowed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_widowed'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_widowed_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_widowed': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_widowed_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_widowed_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['RELATIONSHIP_single'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['RELATIONSHIP_single'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_relationship_single_step1 = pd.DataFrame({'index': index_list, 'llm_relationship_single': llm_response_list})\n",
    "\n",
    "with open('llm_relationship_single_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_relationship_single_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_employed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_employed'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_employed_step1 = pd.DataFrame({'index': index_list, 'llm_employment_employed': llm_response_list})\n",
    "\n",
    "with open('llm_employment_employed_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_employed_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_underemployed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_underemployed'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_underemployed_step1 = pd.DataFrame({'index': index_list, 'llm_employment_underemployed': llm_response_list})\n",
    "\n",
    "with open('llm_employment_underemployed_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_underemployed_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_unemployed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_unemployed'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_unemployed_step1 = pd.DataFrame({'index': index_list, 'llm_employment_unemployed': llm_response_list})\n",
    "\n",
    "with open('llm_employment_unemployed_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_unemployed_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_disability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_disability'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_disability_step1 = pd.DataFrame({'index': index_list, 'llm_employment_disability': llm_response_list})\n",
    "\n",
    "with open('llm_employment_disability_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_disability_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_retired'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_retired'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_retired_step1 = pd.DataFrame({'index': index_list, 'llm_employment_retired': llm_response_list})\n",
    "\n",
    "with open('llm_employment_retired_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_retired_step1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_student'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "llm_response_list = []\n",
    "system_message = \"You are an information extract tool that follows instructions very well and is specifically trained to extract social determinants of health elements from hospital generated free-text.\"\n",
    "for index, row in final_df[final_df['EMPLOYMENT_student'] == True].iterrows():\n",
    "    free_text = row['text']\n",
    "    user_message = step1_query_optimized.format(free_text=free_text)\n",
    "    openai_message = create_prompt(system_message, user_message)\n",
    "    response = send_message(openai_message, deployment_name)\n",
    "    \n",
    "    index_list.append(index)\n",
    "    llm_response_list.append(response)\n",
    "    print(free_text)\n",
    "    print(response)\n",
    "    print()\n",
    "\n",
    "llm_employment_student_step1 = pd.DataFrame({'index': index_list, 'llm_employment_student': llm_response_list})\n",
    "\n",
    "with open('llm_employment_student_step1.pkl', 'wb') as file:\n",
    "    pickle.dump(llm_employment_student_step1, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_insights = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_nonadverse_step1.pkl', 'rb') as file:\n",
    "    llm_employment_nonadverse_step1 = pickle.load(file)\n",
    "\n",
    "recall_insights['llm_employment_nonadverse_step1'] = sum(llm_employment_nonadverse_step1['llm_employment_nonadverse'] == 'YES')/len(llm_employment_nonadverse_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_adverse_step1.pkl', 'rb') as file:\n",
    "    llm_employment_adverse_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_adverse_step1'] = sum(llm_employment_adverse_step1['llm_employment_adverse'] == 'YES')/len(llm_employment_adverse_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_employed_step1.pkl', 'rb') as file:\n",
    "    llm_employment_employed_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_employed_step1'] = sum(llm_employment_employed_step1['llm_employment_employed'] == 'YES')/len(llm_employment_employed_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_retired_step1.pkl', 'rb') as file:\n",
    "    llm_employment_retired_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_retired_step1'] = sum(llm_employment_retired_step1['llm_employment_retired'] == 'YES')/len(llm_employment_retired_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_student_step1.pkl', 'rb') as file:\n",
    "    llm_employment_student_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_student_step1'] = sum(llm_employment_student_step1['llm_employment_student'] == 'YES')/len(llm_employment_student_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_underemployed_step1.pkl', 'rb') as file:\n",
    "    llm_employment_underemployed_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_underemployed_step1'] = sum(llm_employment_underemployed_step1['llm_employment_underemployed'] == 'YES')/len(llm_employment_underemployed_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_employment_unemployed_step1.pkl', 'rb') as file:\n",
    "    llm_employment_unemployed_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_employment_unemployed_step1'] = sum(llm_employment_unemployed_step1['llm_employment_unemployed'] == 'YES')/len(llm_employment_unemployed_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_housing_poor_step1.pkl', 'rb') as file:\n",
    "    llm_housing_poor_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_housing_poor_step1'] = sum(llm_housing_poor_step1['llm_housing_poor'] == 'YES')/len(llm_housing_poor_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_adverse_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_adverse_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_adverse_step1'] = sum(llm_relationship_adverse_step1['llm_relationship_adverse'] == 'YES')/len(llm_relationship_adverse_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_divorced_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_divorced_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_divorced_step1'] = sum(llm_relationship_divorced_step1['llm_relationship_divorced'] == 'YES')/len(llm_relationship_divorced_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_married_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_married_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_married_step1'] = sum(llm_relationship_married_step1['llm_relationship_married'] == 'YES')/len(llm_relationship_married_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_nonadverse_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_nonadverse_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_nonadverse_step1'] = sum(llm_relationship_nonadverse_step1['llm_relationship_nonadverse'] == 'YES')/len(llm_relationship_nonadverse_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_partnered_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_partnered_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_partnered_step1'] = sum(llm_relationship_partnered_step1['llm_relationship_partnered'] == 'YES')/len(llm_relationship_partnered_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_single_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_single_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_single_step1'] = sum(llm_relationship_single_step1['llm_relationship_single'] == 'YES')/len(llm_relationship_single_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_relationship_widowed_step1.pkl', 'rb') as file:\n",
    "    llm_relationship_widowed_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_relationship_widowed_step1'] = sum(llm_relationship_widowed_step1['llm_relationship_widowed'] == 'YES')/len(llm_relationship_widowed_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_transportation_distance_step1.pkl', 'rb') as file:\n",
    "    llm_transportation_distance_step1 = pickle.load(file)\n",
    "    \n",
    "recall_insights['llm_transportation_distance_step1'] = sum(llm_transportation_distance_step1['llm_transportation_distance'] == 'YES')/len(llm_transportation_distance_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdoh-guevera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
