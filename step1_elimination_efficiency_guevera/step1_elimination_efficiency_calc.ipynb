{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the groundtruth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_ground_truth = pd.read_csv('../eval_employment_prompt.csv')\n",
    "relation_ground_truth = pd.read_csv('../eval_relationship_prompt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_df = relation_ground_truth[['RELATIONSHIP_nonadverse', 'RELATIONSHIP_adverse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = employment_ground_truth.join(relation_df, on='index', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm_0_500_step1.pkl', 'rb') as file:\n",
    "    llm_0_500_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_500_1000_step1.pkl', 'rb') as file:\n",
    "    llm_500_1000_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_1000_1500_step1.pkl', 'rb') as file:\n",
    "    llm_1000_1500_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_1500_1622_step1.pkl', 'rb') as file:\n",
    "    llm_1500_1622_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_1622_1977_step1.pkl', 'rb') as file:\n",
    "    llm_1622_1977_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_1977_2254_step1.pkl', 'rb') as file:\n",
    "    llm_1977_2254_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_2254_2500_step1.pkl', 'rb') as file:\n",
    "    llm_2254_2500_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_2500_2628_step1.pkl', 'rb') as file:\n",
    "    llm_2500_2628_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_2628_3000_step1.pkl', 'rb') as file:\n",
    "    llm_2628_3000_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3000_3485_step1.pkl', 'rb') as file:\n",
    "    llm_3000_3485_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3485_3500_step1.pkl', 'rb') as file:\n",
    "    llm_3485_3500_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3500_3576_step1.pkl', 'rb') as file:\n",
    "    llm_3500_3576_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3576_3607_step1.pkl', 'rb') as file:\n",
    "    llm_3576_3607_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3607_3648_step1.pkl', 'rb') as file:\n",
    "    llm_3607_3648_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3648_3885_step1.pkl', 'rb') as file:\n",
    "    llm_3648_3885_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3885_3916_step1.pkl', 'rb') as file:\n",
    "    llm_3885_3916_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_3916_4000_step1.pkl', 'rb') as file:\n",
    "    llm_3916_4000_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_4000_4500_step1.pkl', 'rb') as file:\n",
    "    llm_4000_4500_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_4500_5000_step1.pkl', 'rb') as file:\n",
    "    llm_4500_5000_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_5000_5293_step1.pkl', 'rb') as file:\n",
    "    llm_5000_5293_step1 = pickle.load(file)\n",
    "\n",
    "with open('llm_5293_5321_step1.pkl', 'rb') as file:\n",
    "    llm_5293_5321_step1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_0_500_step1 = llm_0_500_step1.rename(columns={'llm_0_500_step1': 'result'})\n",
    "llm_500_1000_step1 = llm_500_1000_step1.rename(columns={'llm_500_1000_step1': 'result'})\n",
    "llm_1000_1500_step1 = llm_1000_1500_step1.rename(columns={'llm_1000_1500_step1': 'result'})\n",
    "llm_1500_1622_step1 = llm_1500_1622_step1.rename(columns={'llm_1500_2000_step1': 'result'})\n",
    "llm_1622_1977_step1 = llm_1622_1977_step1.rename(columns={'llm_1622_2000_step1': 'result'})\n",
    "llm_1977_2254_step1 = llm_1977_2254_step1.rename(columns={'llm_1977_2500_step1': 'result'})\n",
    "llm_2254_2500_step1 = llm_2254_2500_step1.rename(columns={'llm_2254_2500_step1': 'result'})\n",
    "llm_2500_2628_step1 = llm_2500_2628_step1.rename(columns={'llm_2500_3000_step1': 'result'})\n",
    "llm_2628_3000_step1 = llm_2628_3000_step1.rename(columns={'llm_2628_3000_step1': 'result'})\n",
    "llm_3000_3485_step1 = llm_3000_3485_step1.rename(columns={'llm_3000_3500_step1': 'result'})\n",
    "llm_3485_3500_step1 = llm_3485_3500_step1.rename(columns={'llm_3485_3500_step1': 'result'})\n",
    "llm_3500_3576_step1 = llm_3500_3576_step1.rename(columns={'llm_3500_4000_step1': 'result'})\n",
    "llm_3576_3607_step1 = llm_3576_3607_step1.rename(columns={'llm_3576_4000_step1': 'result'})\n",
    "llm_3607_3648_step1 = llm_3607_3648_step1.rename(columns={'llm_3607_4000_step1': 'result'})\n",
    "llm_3648_3885_step1 = llm_3648_3885_step1.rename(columns={'llm_3648_4000_step1': 'result'})\n",
    "llm_3885_3916_step1 = llm_3885_3916_step1.rename(columns={'llm_3885_4000_step1': 'result'})\n",
    "llm_3916_4000_step1 = llm_3916_4000_step1.rename(columns={'llm_3916_4000_step1': 'result'})\n",
    "llm_4000_4500_step1 = llm_4000_4500_step1.rename(columns={'llm_4000_4500_step1': 'result'})\n",
    "llm_4500_5000_step1 = llm_4500_5000_step1.rename(columns={'llm_4500_5000_step1': 'result'})\n",
    "llm_5000_5293_step1 = llm_5000_5293_step1.rename(columns={'llm_5000_5321_step1': 'result'})\n",
    "llm_5293_5321_step1 = llm_5293_5321_step1.rename(columns={'llm_5293_5321_step1': 'result'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.concat([llm_0_500_step1, llm_500_1000_step1, llm_1000_1500_step1, llm_1500_1622_step1, llm_1622_1977_step1, llm_1977_2254_step1, llm_2254_2500_step1,\n",
    "           llm_2500_2628_step1, llm_2628_3000_step1, llm_3000_3485_step1, llm_3485_3500_step1, llm_3500_3576_step1, llm_3576_3607_step1, llm_3607_3648_step1,\n",
    "           llm_3648_3885_step1, llm_3885_3916_step1, llm_3916_4000_step1, llm_4000_4500_step1, llm_4500_5000_step1, llm_5000_5293_step1, llm_5293_5321_step1],\n",
    "          axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "result\n",
       "NO                                                                                                                                                                                                                                4769\n",
       "YES                                                                                                                                                                                                                                548\n",
       "EMPLOYMENT: Unable to determine\\nTRANSPORTATION: Unable to determine\\nHOUSING: Unable to determine\\nMARITAL_STATUS: Single\\nRELATIONSHIP_CONDITION: NonAdverse\\nEMPLOYMENT_CONDITION: Unable to determine\\n\\nFinal Output: YES       1\n",
       "EMPLOYMENT: Disability\\nTRANSPORTATION: N/A\\nHOUSING: N/A\\nMARITAL_STATUS: N/A\\nRELATIONSHIP_CONDITION: N/A\\nEMPLOYMENT_CONDITION: N/A\\n\\nFinal Output: YES                                                                          1\n",
       "EMPLOYMENT: Employed\\nTRANSPORTATION: N/A\\nHOUSING: N/A\\nMARITAL_STATUS: N/A\\nRELATIONSHIP_CONDITION: N/A\\nEMPLOYMENT_CONDITION: N/A\\n\\nFinal Output: YES                                                                            1\n",
       "HOUSING: Poor\\nMARITAL_STATUS: Single\\nRELATIONSHIP_CONDITION: NonAdverse\\nEMPLOYMENT_CONDITION: NonAdverse\\n\\nOutput: YES                                                                                                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df['result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962601014846834"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_df[predicted_df['result'] == 'NO'])/len(predicted_df['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results from prediction and groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yes_records = final_df[(final_df['TRANSPORTATION_distance'] == True) | (final_df['TRANSPORTATION_resource'] == True) | (final_df['TRANSPORTATION_other'] == True) |\n",
    "                            (final_df['EMPLOYMENT_nonadverse'] == True) | (final_df['EMPLOYMENT_adverse'] == True) | (final_df['HOUSING_poor'] == True) |\n",
    "                            (final_df['HOUSING_undomiciled'] == True) | (final_df['EMPLOYMENT_employed'] == True) | (final_df['EMPLOYMENT_underemployed'] == True) |\n",
    "                            (final_df['EMPLOYMENT_unemployed'] == True) | (final_df['EMPLOYMENT_disability'] == True) | (final_df['EMPLOYMENT_retired'] == True) |\n",
    "                            (final_df['EMPLOYMENT_student'] == True)]\n",
    "\n",
    "final_yes_records_index = final_yes_records.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_no_records = final_df[~final_df.index.isin(final_yes_records_index)]\n",
    "final_no_records_index = final_no_records.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_no_records = predicted_df[predicted_df['index'].isin(final_no_records_index)]\n",
    "predicted_yes_records = predicted_df[predicted_df['index'].isin(final_yes_records_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO Predictions Accuracy:  0.9076542269611576\n"
     ]
    }
   ],
   "source": [
    "correct_no_prediction = predicted_no_records[predicted_no_records['result'] == 'NO']\n",
    "print('NO Predictions Accuracy: ', len(correct_no_prediction)/len(predicted_no_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES Predictions Accuracy:  0.9710144927536232\n"
     ]
    }
   ],
   "source": [
    "correct_yes_prediction = predicted_yes_records[predicted_yes_records['result'] == 'YES']\n",
    "print('YES Predictions Accuracy: ', len(correct_yes_prediction)/len(predicted_yes_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the global recall value among YES or NO\n",
    "# Run the optimized query on Ahsan data as well as try to find the start/end position of the attribute in each category\n",
    "# Wait for Ivan to give the categories/attributes which I need to target for step 1 efficiency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdoh-guevera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
